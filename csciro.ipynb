{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7875e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip download -d packages transformers\n",
    "!pip install -q -U transformers --no-index -f /kaggle/input/metadino-v3-convnext/pytorch/default/3/packages\n",
    "# !pip install -q -U transformers xgboost opencv-python 'numpy<2.0' 'pandas>=2.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d95b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import huggingface_hub\n",
    "# huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4022e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = '/kaggle/input/csiro-biomass'\n",
    "PATH_TRAIN_CSV = os.path.join(PATH_DATA, 'train.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(PATH_DATA, 'train')\n",
    "PATH_TEST_IMG = os.path.join(PATH_DATA, 'test')\n",
    "\n",
    "df = pd.read_csv(PATH_TRAIN_CSV)\n",
    "print(f\"Dataset size: {df.shape}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLS = [c for c in df.columns if c not in ['image_id', 'Image']]\n",
    "print(f\"Target columns: {TARGET_COLS}\")\n",
    "print(f\"Number of targets: {len(TARGET_COLS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude non-numeric or identifier columns from histogram plotting\n",
    "cols_to_plot = [col for col in TARGET_COLS if col not in ['sample_id', 'image_path', 'State', 'target_name']]\n",
    "\n",
    "for col in cols_to_plot:\n",
    "    plt.figure(figsize=(8, 3)) # Create a new figure for each histogram\n",
    "    plt.hist(df[col].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel(col, fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.title(f'{col} Distribution', fontsize=14, fontweight='bold')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.xticks(rotation=45, ha=\"right\") # Rotate x-axis labels\n",
    "    plt.tight_layout() # Adjust layout to prevent overlap\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_plot = ['State', 'target_name']\n",
    "n_rows, n_cols = 1, len(cols_to_plot)\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 4 * n_rows))\n",
    "\n",
    "# Ensure axes is an array even for a single subplot\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, col in zip(axes, cols_to_plot):\n",
    "    counts = df[col].value_counts()\n",
    "    ax.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=140)\n",
    "    ax.set_title(f'Distribution of {col}', fontsize=14, fontweight='bold')\n",
    "    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "grouped_train_data = df.groupby('target_name')\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for target_name, group_data in grouped_train_data:\n",
    "    sns.histplot(data=group_data, x='target', kde=True, label=target_name)\n",
    "\n",
    "plt.title('Distribution of Target for Each Target Name Class')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(title='Target Name')\n",
    "plt.grid(True) # Added grid here\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(df_sample, n=12, path_img=PATH_DATA):\n",
    "    \"\"\"Displays a linear sampling of images sorted by target value.\"\"\"\n",
    "\n",
    "    # Sort the DataFrame by the 'target' column\n",
    "    df_sorted = df_sample.sort_values(by='target').reset_index(drop=True)\n",
    "\n",
    "    # Perform linear sampling\n",
    "    indices_to_show = np.linspace(0, len(df_sorted) - 1, n, dtype=int)\n",
    "    df_to_show = df_sorted.iloc[indices_to_show]\n",
    "\n",
    "    # Determine the number of rows and columns for subplots\n",
    "    n_cols = 3  # You can adjust this number\n",
    "    n_rows = (n + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Remove unused subplots if any\n",
    "    for i in range(n, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    for i, (idx, row) in enumerate(df_to_show.iterrows()):\n",
    "        # Use image_path directly (includes train/ID....jpg)\n",
    "        img_path = os.path.join(path_img, row['image_path'])\n",
    "\n",
    "        if os.path.exists(img_path):\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            axes[i].imshow(img)\n",
    "            # Include the target value in the title\n",
    "            title = f\"ID: {row['sample_id']}\\nTarget: {row['target']:.2f}\"\n",
    "            axes[i].set_title(title, fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage: Show 12 images linearly sampled based on target value\n",
    "show_images(df, n=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539d71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Define the feature extraction pipeline\n",
    "feature_extractor = pipeline(\n",
    "    # model=\"facebook/dinov3-convnext-tiny-pretrain-lvd1689m\",\n",
    "    model=\"/kaggle/input/metadino-v3-convnext/pytorch/default/3/dinov3-convnext-tiny-pretrain-lvd1689m\",\n",
    "    task=\"image-feature-extraction\",\n",
    "    device=0 if torch.cuda.is_available() else -1 # Use GPU if available\n",
    ")\n",
    "\n",
    "def extract_image_features_pipeline(image_path, feature_extractor, path_data):\n",
    "    \"\"\"\n",
    "    Splits an image into two 1000x1000 parts and extracts features from each using a pipeline.\n",
    "    \"\"\"\n",
    "    full_image_path = os.path.join(path_data, image_path)\n",
    "    img = Image.open(full_image_path)#.convert('RGB')\n",
    "\n",
    "    # Split the image into two 1000x1000 parts\n",
    "    width, height = img.size\n",
    "    img1 = img.crop((0, 0, width // 2, height))\n",
    "    img2 = img.crop((width // 2, 0, width, height))\n",
    "\n",
    "    # The pipeline expects PIL Images or paths, use 'inputs'\n",
    "    extracted_features = feature_extractor(inputs=[img1, img2], pool=True)\n",
    "    # extracted_features = feature_extractor(inputs=[img], pool=True)\n",
    "    # print(f\"extracted_features: {np.array(extracted_features).shape}\")\n",
    "\n",
    "    # Concatenate features from both parts\n",
    "    combined_features = list(np.array(extracted_features).flatten())\n",
    "    # print(f\"combined_features: {len(combined_features)}\")\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "print(\"Image feature extraction function defined using pipeline.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a789e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for all images\n",
    "image_features = {}\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    image_path = row['image_path']\n",
    "    # Use the pipeline function\n",
    "    features = extract_image_features_pipeline(image_path, feature_extractor, PATH_DATA)\n",
    "    # Use the sample_id as the key for the features\n",
    "    image_features[row['sample_id']] = features\n",
    "\n",
    "print(\"Image feature extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee83c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image features dictionary to a DataFrame\n",
    "image_features_df = pd.DataFrame.from_dict(image_features, orient='index')\n",
    "image_features_df.index.name = 'sample_id'\n",
    "image_features_df.columns = [f'img_feature_{i}' for i in range(image_features_df.shape[1])]\n",
    "\n",
    "# One-hot encode the 'target_name' column\n",
    "df_one_hot = pd.get_dummies(df['target_name'], prefix='target_name').astype(int) # Convert to int\n",
    "\n",
    "# Merge the image features and one-hot encoded features with the original DataFrame\n",
    "df_combined = df.merge(image_features_df, on='sample_id', how='left')\n",
    "df_combined = df_combined.merge(df_one_hot, left_index=True, right_index=True)\n",
    "\n",
    "print(\"Image features and one-hot encoded target names combined with the original DataFrame.\")\n",
    "display(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa28b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Flatten all image features into a single Series\n",
    "image_features_cols = [col for col in df_combined.columns if col.startswith(\"img_feature_\")]\n",
    "all_features_flat = image_features_df[image_features_cols].values.flatten()\n",
    "all_features_series = pd.Series(all_features_flat)\n",
    "\n",
    "# Plot a single histogram for all features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(all_features_series, kde=True, bins=100) # Adjust bins as needed\n",
    "plt.title('Distribution of All Extracted Image Feature Values')\n",
    "plt.xlabel('Feature Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f4a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate image features and other features\n",
    "image_feature_cols = [col for col in df_combined.columns if col.startswith('img_feature_')]\n",
    "other_features_cols = [col for col in df_combined.columns if col.startswith('target_name_')]\n",
    "\n",
    "X_image_features = df_combined[image_feature_cols]\n",
    "X_other_features = df_combined[other_features_cols]\n",
    "\n",
    "# Standardize the image features before applying PCA\n",
    "scaler = StandardScaler()\n",
    "X_image_scaled = scaler.fit_transform(X_image_features)\n",
    "\n",
    "# Apply PCA to reduce dimensionality\n",
    "# You can adjust the number of components (n_components)\n",
    "pca = PCA(n_components=75) # Example: Reduce components by 20x\n",
    "X_image_pca = pca.fit_transform(X_image_scaled)\n",
    "\n",
    "# Convert the PCA reduced features to a DataFrame\n",
    "X_image_pca_df = pd.DataFrame(\n",
    "    X_image_pca, index=df_combined.index,\n",
    "    columns=[f'pca_img_feature_{i}' for i in range(pca.n_components)])\n",
    "\n",
    "# Combine the PCA reduced image features with the other features\n",
    "X_combined_pca = pd.concat([X_other_features, X_image_pca_df], axis=1)\n",
    "\n",
    "print(f\"Original number of image features: {X_image_features.shape[1]}\")\n",
    "print(f\"Reduced number of image features after PCA: {X_image_pca_df.shape[1]}\")\n",
    "print(f\"Total number of features for regression after PCA: {X_combined_pca.shape[1]}\")\n",
    "\n",
    "# Display the first few rows of the combined feature DataFrame after PCA\n",
    "display(X_combined_pca.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
